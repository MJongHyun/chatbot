import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import ast
from collections import Counter
import matplotlib.pyplot as plt


# --- 1. ì•± ì„¤ì • ---
st.set_page_config(layout="wide")
st.title("ë¬¸ì„œ ê¸°ë°˜ ì±—ë´‡ ë‹µë³€ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

# --- 2. ë°ì´í„° ì²˜ë¦¬ ë° ì‹œê°í™” í•¨ìˆ˜ ---

# ì›ë³¸ í•¨ìˆ˜ (ë³€ê²½ ì—†ìŒ)
def intent_v1_v2_true_false_res(cbot_res_df):
    df = cbot_res_df.copy()
    idxTFDF = pd.DataFrame()
    for idx in df['index'].tolist():
        mask = df['index'] == idx
        correct_TF_v2, correct_TF_v1 = df.loc[mask, 'correct_TF'].iloc[0], df.loc[mask, 'correct_TF_v1'].iloc[0]
        try:
            correct_TF_v2_list = set(ast.literal_eval(df.loc[mask, 'v2_int_code'].iloc[0]))
        except (ValueError, SyntaxError):
            correct_TF_v2_list = set()
        correct_TF_v1_list = df.loc[mask, 'qu_intent'].iloc[0]
        v1_DF = pd.DataFrame([correct_TF_v1_list], columns=['code']); v1_DF['index'] = idx; v1_DF['div'] = 'V1'; v1_DF['TF'] = correct_TF_v1
        if correct_TF_v2_list:
            v2_DF = pd.DataFrame(list(correct_TF_v2_list), columns=['code']); v2_DF['index'] = idx; v2_DF['div'] = 'V2'; v2_DF['TF'] = correct_TF_v2
            idxTFDF = pd.concat([idxTFDF, v1_DF, v2_DF], axis=0)
        else:
            idxTFDF = pd.concat([idxTFDF, v1_DF], axis=0)
    idxTFDF = idxTFDF.reset_index(drop=True)
    x_res_deno = idxTFDF[['code']].value_counts().reset_index(name='deno')
    x_res_nume = idxTFDF[idxTFDF['TF'] == True][['code']].value_counts().reset_index(name='nume')
    x_nume_deno = pd.merge(x_res_deno, x_res_nume, on='code', how='left').fillna(0)
    return idxTFDF, x_nume_deno

# ì›ë³¸ í•¨ìˆ˜ (ë³€ê²½ ì—†ìŒ)
def scatter_plot_res_make(x_nume_deno):
    df = x_nume_deno.copy()
    if not df.empty:
        plot_df_final = df.rename(columns={'code': 'TypeName', 'deno': 'TotalInquiries', 'nume': 'CorrectAnswers'})
        plot_df_final['AccuracyRate'] = np.round(plot_df_final['CorrectAnswers'] / plot_df_final['TotalInquiries'] * 100, 2)
        return plot_df_final.drop_duplicates(subset=['TypeName']).reset_index(drop=True)
    return pd.DataFrame()


# [ìˆ˜ì •ë¨] ì‚¬ë¶„ë©´ í• ë‹¹ ë¡œì§ì„ ë¶„ë¦¬í•˜ê³ , ë‘ ê°œì˜ ê¸°ì¤€ì„ ì„ ë°›ë„ë¡ ìˆ˜ì •
def res_excel_df_v1_v2_scatter(_cbot_row_idxTFDF, _cbot_scatter_df, _cbot_res_df, _cbot_answer_df, llm_judge_threshold, ref_docs_threshold):
    v2_row_res = _cbot_row_idxTFDF[_cbot_row_idxTFDF['div'] == 'V2']
    v2_all_code = pd.merge(_cbot_res_df, v2_row_res[['code', 'index']].drop_duplicates(), on='index')
    v2_all_code_g = np.round(v2_all_code.groupby('code')['v2_judge_mean_score'].mean(), 2).reset_index(name='all_v2_score')
    v2_code_g = v2_all_code_g.rename(columns={'code': 'TypeName'})
    r1 = pd.merge(_cbot_answer_df, v2_code_g, on='TypeName', how='inner')
    r2 = pd.merge(_cbot_scatter_df, r1, on='TypeName', how='inner')

    if r2.empty: return pd.DataFrame()

    # ì‚¬ë¶„ë©´ í• ë‹¹ í•¨ìˆ˜ (ë‘ ê¸°ì¤€ì„ ì„ ì‚¬ìš©)
    def assign_quadrant(row):
        if row['TotalInquiries'] > ref_docs_threshold and row['all_v2_score'] > llm_judge_threshold: return '1ì‚¬ë¶„ë©´: ë§ìŒ/ë†’ìŒ'
        if row['TotalInquiries'] <= ref_docs_threshold and row['all_v2_score'] > llm_judge_threshold: return '2ì‚¬ë¶„ë©´: ì ìŒ/ë†’ìŒ'
        if row['TotalInquiries'] <= ref_docs_threshold and row['all_v2_score'] <= llm_judge_threshold: return '3ì‚¬ë¶„ë©´: ì ìŒ/ë‚®ìŒ'
        if row['TotalInquiries'] > ref_docs_threshold and row['all_v2_score'] <= llm_judge_threshold: return '4ì‚¬ë¶„ë©´: ë§ìŒ/ë‚®ìŒ'
        return 'N/A'

    r2['Quadrant'] = r2.apply(assign_quadrant, axis=1)
    r2.rename(columns={'TypeName': 'ë¬¸ì„œì½”ë“œ', 'TotalInquiries': 'ì „ì²´ ì°¸ê³  ë¬¸ì„œ ìˆ˜', 'CorrectAnswers': 'LLM-Cor ì°¸ê³  ë¬¸ì„œ ìˆ˜', 'AccuracyRate': 'ì •í™•ë„', 'all_v2_score': 'LLM í‰ê·  LLM Judge', 'document_data': 'ë“±ë¡í•œ ë¬¸ì„œ', 'Quadrant': 'ì‚¬ë¶„ë©´ìœ í˜•'}, inplace=True)
    return r2[['ì‚¬ë¶„ë©´ìœ í˜•', 'ë¬¸ì„œì½”ë“œ', 'ì „ì²´ ì°¸ê³  ë¬¸ì„œ ìˆ˜', 'LLM-Cor ì°¸ê³  ë¬¸ì„œ ìˆ˜', 'ì •í™•ë„', 'LLM í‰ê·  LLM Judge', 'ë“±ë¡í•œ ë¬¸ì„œ']]

# [ìˆ˜ì •ë¨] í”Œë¡¯ í•¨ìˆ˜ê°€ ë‘ ê°œì˜ ê¸°ì¤€ì„  ê°’ì„ ì§ì ‘ ë°›ë„ë¡ ìˆ˜ì •
def interactive_scatter_plot(plot_df, service_name, llm_judge_score_threshold, ref_docs_threshold):
    fig = go.Figure()
    quadrant_order = ['1ì‚¬ë¶„ë©´: ë§ìŒ/ë†’ìŒ', '2ì‚¬ë¶„ë©´: ì ìŒ/ë†’ìŒ', '3ì‚¬ë¶„ë©´: ì ìŒ/ë‚®ìŒ', '4ì‚¬ë¶„ë©´: ë§ìŒ/ë‚®ìŒ']
    colors = ['#2ca02c', '#1f77b4', '#ff7f0e', '#d62728'] # ë§/ë†’(ì´ˆë¡), ì /ë†’(íŒŒë‘), ì /ë‚®(ì£¼í™©), ë§/ë‚®(ë¹¨ê°•)

    for quadrant_name, color in zip(quadrant_order, colors):
        subset = plot_df[plot_df['ì‚¬ë¶„ë©´ìœ í˜•'] == quadrant_name]
        if not subset.empty:
            hovertemplate = "<b>%{customdata[0]}</b><br>ì°¸ê³  ë¬¸ì„œ ìˆ˜: %{x}<br>LLM ì ìˆ˜: %{y:.2f}<extra></extra>"
            fig.add_trace(go.Scatter(
                x=subset['ì „ì²´ ì°¸ê³  ë¬¸ì„œ ìˆ˜'],
                y=subset['LLM í‰ê·  LLM Judge'],
                mode='markers',
                name=quadrant_name,
                marker=dict(size=12, color=color),
                customdata=np.stack((subset['ë¬¸ì„œì½”ë“œ'], subset['ì •í™•ë„']), axis=-1),
                hovertemplate=hovertemplate
            ))

    # Xì¶•ê³¼ Yì¶• ê¸°ì¤€ì„ ì„ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê°’ìœ¼ë¡œ ì„¤ì •
    fig.add_vline(x=ref_docs_threshold, line_width=1.5, line_dash="dash", line_color="dimgray", annotation_text=f"ë¬¸ì„œ ìˆ˜ ê¸°ì¤€ì„ : {ref_docs_threshold:.0f}")
    fig.add_hline(y=llm_judge_score_threshold, line_width=1.5, line_dash="dash", line_color="dimgray", annotation_text=f"ì ìˆ˜ ê¸°ì¤€ì„ : {llm_judge_score_threshold:.2f}")

    fig.update_layout(
        title=f'<b>{service_name} ë¬¸ì„œë³„ ë‹µë³€ ì ìˆ˜ ê²°ê³¼ ë¶„ì„</b>',
        xaxis_title='ì°¸ê³ ëœ ë¬¸ì„œ ìˆ˜ (ê°œ)',
        yaxis_title='LLM Judge í‰ê·  ì ìˆ˜',
        legend_title_text='<b>ì‚¬ë¶„ë©´ ìœ í˜•</b>',
        height=600
    )
    st.plotly_chart(fig, use_container_width=True)

# --- 3. ë°ì´í„° ë¡œë“œ ---
# íŒŒì¼ ê²½ë¡œ (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
try:
    cbot_answer_file = './data/c_bot_code_fin.parquet'
    c_df_file = './data/c_df_all.parquet'
    qdf_file = './data/c_bot_test_cluster_res_0625.xlsx'
    keyword_file = './data/c_bot_keyword_check_0625.xlsx'

    cbot_answer_df = pd.read_parquet(cbot_answer_file).rename(columns={'document_name': 'TypeName'})[['TypeName', 'document_data']]
    c_df = pd.read_parquet(c_df_file)
    qDF_refine = pd.read_excel(qdf_file)
    keywordAllDF = pd.read_excel(keyword_file)
except Exception as e:
    st.error(f"íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    st.stop()

# --- 4. ëŒ€ì‹œë³´ë“œ UI ë° ë¡œì§ ---

# 4-1. ì‚°ì ë„ ìƒì„±
st.header("ë¬¸ì„œë³„ ë‹µë³€ í‰ê°€")
st.info("ì•„ë˜ ì‚°ì ë„ëŠ” ë¬¸ì˜ì— ë”°ë¥¸ ë‹µë³€ì‹œ ê° ë¬¸ì„œì˜ 'ì°¸ê³ ëœ íšŸìˆ˜'ì™€ 'LLM Judge í‰ê·  ì ìˆ˜'ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤. \n ê¸°ì¤€ì„ ì„ ì¡°ì ˆí•˜ì—¬ ì‚¬ë¶„ë©´ì„ ì¬êµ¬ì„±í•˜ê³ , ë¬¸ì„œë¥¼ ê·¸ë£¹ë³„ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì´ˆê¸°ê°’ :  X, Y ì¤‘ì•™ ê°’ìœ¼ë¡œ ì ìš©)")

# [ìˆ˜ì •ë¨] ê¸°ì¤€ì„  ì„¤ì •ì„ ìœ„í•œ UIì™€ ë¡œì§
# (1) ì‚¬ë¶„ë©´ ê³„ì‚° ì „ ì›ë³¸ ë°ì´í„° ìƒì„±
cbot_row_idxTFDF, cbot_idxTFDF_pre = intent_v1_v2_true_false_res(c_df)
cbot_scatter_df_pre = scatter_plot_res_make(cbot_idxTFDF_pre)

# (2) ì´ˆê¸° ë°ì´í„°í”„ë ˆì„ ìƒì„±ì„ ìœ„í•´ ì„ì‹œê°’(0)ìœ¼ë¡œ í•¨ìˆ˜ í˜¸ì¶œ (ì‚¬ë¶„ë©´ ì œì™¸ ë°ì´í„°ë§Œ í•„ìš”)
base_df = res_excel_df_v1_v2_scatter(cbot_row_idxTFDF, cbot_scatter_df_pre, c_df, cbot_answer_df, 0, 0)

# (3) ë°ì´í„° ì¤‘ì•™ê°’ì„ ê¸°ì¤€ì„ ì˜ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
if not base_df.empty:
    ref_docs_median_default = base_df['ì „ì²´ ì°¸ê³  ë¬¸ì„œ ìˆ˜'].median()
    llm_judge_score_median_default = base_df['LLM í‰ê·  LLM Judge'].median()
else:
    ref_docs_median_default = 10.0  # ë°ì´í„° ì—†ì„ ì‹œ ê¸°ë³¸ê°’
    llm_judge_score_median_default = 4.2  # ë°ì´í„° ì—†ì„ ì‹œ ê¸°ë³¸ê°’

col1, col2 = st.columns([1, 3])
with col1:
    st.markdown("##### ğŸ“Š ê¸°ì¤€ì„  ì„¤ì •")
    ref_docs_input = st.number_input(
        label="ì°¸ê³ ëœ ë¬¸ì„œ ìˆ˜ ê¸°ì¤€ì„ ",
        min_value=0,
        value=int(ref_docs_median_default),  # ì¤‘ì•™ê°’ìœ¼ë¡œ ê¸°ë³¸ê°’ ì„¤ì •
        step=1,
        help="Xì¶• ê¸°ì¤€ì„ ì…ë‹ˆë‹¤. ì´ ê°’ì„ ë³€ê²½í•˜ë©´ ì‚¬ë¶„ë©´ê³¼ ì ì˜ ìƒ‰ìƒì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ë³€ê²½ë©ë‹ˆë‹¤."
    )
    llm_judge_score_input = st.number_input(
        label="LLM Judge ì ìˆ˜ ê¸°ì¤€ì„ ",
        min_value=0.0, max_value=5.0,
        value=float(llm_judge_score_median_default), # ì¤‘ì•™ê°’ìœ¼ë¡œ ê¸°ë³¸ê°’ ì„¤ì •
        step=0.05,
        format="%.2f",
        help="Yì¶• ê¸°ì¤€ì„ ì…ë‹ˆë‹¤. ì´ ê°’ì„ ë³€ê²½í•˜ë©´ ì‚¬ë¶„ë©´ê³¼ ì ì˜ ìƒ‰ìƒì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ë³€ê²½ë©ë‹ˆë‹¤."
    )

# (4) ì‚¬ìš©ìê°€ ì„¤ì •í•œ ê¸°ì¤€ì„ ìœ¼ë¡œ ìµœì¢… ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° ì‹œê°í™”
final_df = res_excel_df_v1_v2_scatter(cbot_row_idxTFDF, cbot_scatter_df_pre, c_df, cbot_answer_df, llm_judge_score_input, ref_docs_input)
interactive_scatter_plot(final_df, 'ì±—ë´‡ ì„±ëŠ¥', llm_judge_score_input, ref_docs_input)


# 4-2. ìƒì„¸ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
st.header("ë¶ˆëª…í™•í•œ ë‹µë³€ ìƒì„¸ ë¶„ì„")
st.info("ì‚°ì ë„ì„ í†µí•´ ë¶„ì„ì´ í•„ìš”í•œ ë¬¸ì„œë¥¼ ì°¾ê³ , ì•„ë˜ì—ì„œ í•´ë‹¹ ë¬¸ì„œ ì½”ë“œë¥¼ ì„ íƒí•˜ì—¬ ìƒì„¸ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”. \n ì•„ë˜ì—ì„œ ì œê³µí•˜ëŠ” ê²°ê³¼ëŠ” 'ì£„ì†¡í•©ë‹ˆë‹¤', 'ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤' ë“± ë¶ˆëª…í™•í•œ ë‹µë³€ì„ ì œê³µí•œ ë¬¸ì˜ì™€ ì£¼ìš” í‚¤ì›Œë“œë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

if final_df.empty:
    st.warning("ìƒì„¸ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
else:
    doc_options = sorted(final_df['ë¬¸ì„œì½”ë“œ'].unique().tolist())
    selected_doc = st.selectbox("ìƒì„¸ ë¶„ì„ì„ ì›í•˜ëŠ” ë¬¸ì„œ ì½”ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:", options=doc_options, key="doc_selector")

    if selected_doc:
        try:
            doc_text = cbot_answer_df[cbot_answer_df['TypeName'] == selected_doc]['document_data'].iloc[0]
            with st.expander("ë“±ë¡í•œ ë¬¸ì„œ ì›ë³¸ ë‚´ìš© ë³´ê¸°"):
                st.markdown(f"```\n{doc_text}\n```")
        except IndexError:
            st.warning("ë“±ë¡í•œ ë¬¸ì„œì˜ ì›ë³¸ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        st.subheader(f"'{selected_doc}' ë¬¸ì„œê°€ ì°¸ê³ ëœ ë¬¸ì˜ì—ì„œ ì¶”ì¶œí•œ ì£¼ìš” í‚¤ì›Œë“œ")
        st.info("í•´ë‹¹ ë¬¸ì„œë¥¼ ì°¸ê³ í•œ ì—¬ëŸ¬ ë¬¸ì˜ ì¤‘, ë¶ˆëª…í™•í•œ ë‹µë³€ì— ì‚¬ìš©ëœ ì£¼ìš” í‚¤ì›Œë“œë¥¼ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤. ë¬¸ì„œ ìˆ˜ì • ì‹œ í™œìš©í•˜ë©´ ì±—ë´‡ì´ ë‹µë³€ì„ ì œê³µí•˜ë„ë¡ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # [ìˆ˜ì •ë¨] head(10)ìœ¼ë¡œ ìƒìœ„ 10ê°œë§Œ í•„í„°ë§í•˜ê³ , dataframe ë†’ì´ë¥¼ ì§€ì •í•´ ìŠ¤í¬ë¡¤ ìƒì„±
        keywords_df = keywordAllDF[keywordAllDF['TypeName'] == selected_doc].sort_values('count', ascending=False).head(10)
        st.dataframe(
            keywords_df[['keyword', 'count']].rename(columns={'keyword': 'í‚¤ì›Œë“œ', 'countã„´': 'ì–¸ê¸‰ íšŸìˆ˜'}),
            height=385, # ë°ì´í„°í”„ë ˆì„ì˜ ë†’ì´ë¥¼ ì§€ì •í•˜ì—¬ 10ê°œ ì´ˆê³¼ ì‹œ ìŠ¤í¬ë¡¤ë°” ìƒì„± (10ê°œì— ë§ì¶° ì¡°ì •)
            use_container_width=False
        )

        st.subheader(f"'{selected_doc}' ë¬¸ì„œê°€ ì°¸ê³ ëœ ë¶ˆëª…í™•í•œ ë‹µë³€ ì›ì¸ ë¶„ì„")
        st.info("í•´ë‹¹ ë¬¸ì„œë¥¼ ì°¸ê³ í•œ ì—¬ëŸ¬ ë¬¸ì˜ ì¤‘ ë¶ˆëª…í™•í•œ ë‹µë³€ì— ë¹„ìŠ·í•œ ì‹¤ë¬¸ì˜ êµ°ì§‘ì •ë³´, ë¬¸ì˜ì™€ ì°¸ê³ ë¬¸ì„œ ë‚´ìš©ê°„ì˜ ìœ ì‚¬ë„ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
        st.info("ì˜ë¯¸ìœ ì‚¬ë„ë„ ë†’ê±°ë‚˜ ì–´íœ˜ìœ ì‚¬ë„ë„ ë†’ì€ ê²½ìš°ì˜ ë¬¸ì˜ë¥¼ í™•ì¸í•˜ì—¬ ë¬¸ì„œ ìˆ˜ì •ì— í™œìš©í•˜ë©´ ì±—ë´‡ì´ ë‹µë³€ì„ ì œê³µí•˜ë„ë¡ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        doc_detail_df = qDF_refine[qDF_refine['TypeName'] == selected_doc].copy()

        st.markdown("##### í•„í„°ë§")
        filter_cols = st.columns(4)

        with filter_cols[0]:
            min_semantic = st.number_input("ì˜ë¯¸ ìœ ì‚¬ë„ â‰¥", min_value=0.0, max_value=1.0, value=0.0, step=0.05, format="%.2f")
        with filter_cols[1]:
            min_lexical = st.number_input("ì–´íœ˜ ìœ ì‚¬ë„ â‰¥", min_value=0.0, max_value=1.0, value=0.0, step=0.05, format="%.2f")

        filtered_df = doc_detail_df[
            (doc_detail_df['semantic_score'] >= min_semantic) &
            (doc_detail_df['lexical_score'] >= min_lexical)
        ]

        display_cols = {
            'question_cluster': 'ìœ ì‚¬ ì‹¤ë¬¸ì˜ êµ°ì§‘ ê²°ê³¼', 'semantic_score': 'ì˜ë¯¸ ìœ ì‚¬ë„', 'lexical_score': 'ì–´íœ˜ ìœ ì‚¬ë„'
        }
        display_cols_exist = {k: v for k, v in display_cols.items() if k in filtered_df.columns}
        st.dataframe(filtered_df[display_cols_exist.keys()].rename(columns=display_cols_exist))
